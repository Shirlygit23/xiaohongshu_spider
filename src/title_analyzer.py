import pandas as pd
from collections import Counter
import os
from datetime import datetime
import re
import jieba
import openpyxl
from openpyxl.styles import PatternFill, Font, Alignment
from openpyxl.chart import PieChart, Reference
from openpyxl.chart.label import DataLabelList
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import matplotlib
from config.base_config import base_config

matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯

class TitleAnalyzer:
    def __init__(self, df):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.df = df
        self.data_dir = base_config.DATA_DIR
        
    def extract_common_phrases(self, titles):
        """æå–æ ‡é¢˜ä¸­çš„å…±æ€§è¯ç»„"""
        # ä½¿ç”¨é…ç½®ä¸­çš„å…³é”®è¯åˆ—è¡¨
        relevant_keywords = base_config.TITLE_RELEVANT_KEYWORDS
        
        # åˆ†è¯å¹¶ç»Ÿè®¡è¯é¢‘
        word_freq = Counter()
        phrase_patterns = []
        
        # ç¬¬ä¸€æ­¥ï¼šå¯¹æ‰€æœ‰æ ‡é¢˜è¿›è¡Œåˆ†è¯
        all_words_in_titles = []
        for title in titles:
            # ä½¿ç”¨jiebaçš„æœç´¢å¼•æ“æ¨¡å¼ï¼Œæ›´å®¹æ˜“è¯†åˆ«çŸ­è¯­
            words = [w for w in jieba.cut_for_search(title) if len(w) > 1]
            all_words_in_titles.append(words)
            word_freq.update(words)
        
        # ç¬¬äºŒæ­¥ï¼šå¯»æ‰¾å…±åŒå‡ºç°çš„è¯ç»„
        common_phrases = []
        for i in range(len(all_words_in_titles)):
            words = all_words_in_titles[i]
            
            # åœ¨å•ä¸ªæ ‡é¢˜å†…å¯»æ‰¾å¯èƒ½çš„è¯ç»„
            for j in range(len(words)-1):
                for k in range(j+1, min(j+4, len(words))):  # æœ€å¤šçœ‹ç›¸é‚»çš„3ä¸ªè¯
                    phrase_words = words[j:k+1]
                    if len(phrase_words) >= 2:  # è‡³å°‘2ä¸ªè¯
                        phrase = ''.join(phrase_words)
                        # æ£€æŸ¥è¿™ä¸ªè¯ç»„åœ¨å…¶ä»–æ ‡é¢˜ä¸­çš„å‡ºç°æ¬¡æ•°
                        count = sum(1 for title in titles if phrase in title)
                        if count >= 2:  # è‡³å°‘åœ¨2ä¸ªæ ‡é¢˜ä¸­å‡ºç°
                            common_phrases.append({
                                'phrase': phrase,
                                'frequency': count,
                                'words': phrase_words,
                                'example_titles': [t for t in titles if phrase in t][:3]  # ä¿å­˜æœ€å¤š3ä¸ªç¤ºä¾‹æ ‡é¢˜
                            })
        
        # ç¬¬ä¸‰æ­¥ï¼šå»é‡å’Œæ’åº
        seen_phrases = set()
        unique_phrases = []
        for p in common_phrases:
            if p['phrase'] not in seen_phrases:
                seen_phrases.add(p['phrase'])
                unique_phrases.append(p)
        
        # æŒ‰é¢‘ç‡å’Œè¯ç»„é•¿åº¦æ’åºï¼ˆä¼˜å…ˆé€‰æ‹©é¢‘ç‡é«˜ä¸”è¾ƒé•¿çš„è¯ç»„ï¼‰
        unique_phrases.sort(key=lambda x: (x['frequency'], len(x['phrase'])), reverse=True)
        
        # ç¬¬å››æ­¥ï¼šè¿‡æ»¤æ‰ä¸å¤Ÿç›¸å…³çš„è¯ç»„
        filtered_phrases = []
        for p in unique_phrases:
            # æ£€æŸ¥è¯ç»„æ˜¯å¦æœ‰æ„ä¹‰
            if len(p['words']) >= 2 and (  # è‡³å°‘2ä¸ªè¯
                # æ¡ä»¶1ï¼šåŒ…å«ç›¸å…³å…³é”®è¯
                any(w in relevant_keywords for w in p['words']) or
                # æ¡ä»¶2ï¼šé«˜é¢‘å‡ºç°ï¼ˆå‡ºç°3æ¬¡ä»¥ä¸Šï¼‰ä¸”è¯ç»„é•¿åº¦åˆé€‚
                (p['frequency'] >= 3 and len(p['phrase']) >= 3) or
                # æ¡ä»¶3ï¼šç‰¹åˆ«é«˜é¢‘ï¼ˆå‡ºç°5æ¬¡ä»¥ä¸Šï¼‰
                p['frequency'] >= 5
            ):
                filtered_phrases.append(p)
        
        return filtered_phrases[:10]  # è¿”å›top 10å…±æ€§è¯ç»„

    def analyze_similar_titles(self):
        """åˆ†æç›¸ä¼¼æ ‡é¢˜"""
        print("\n=== å¼€å§‹æ ‡é¢˜åˆ†æ ===")
        title_analysis = []
        
        # 1. æå–æ‰€æœ‰æ ‡é¢˜çš„å…³é”®è¯
        title_info = {}  # å­˜å‚¨æ ‡é¢˜çš„å…³é”®è¯å’Œç‚¹èµæ•°
        for idx, row in self.df.iterrows():
            title = row['ç¬”è®°æ ‡é¢˜']
            likes = row.get('ç‚¹èµæ•°', 0)  # è·å–ç‚¹èµæ•°
            
            # ç¡®ä¿æ ‡é¢˜æ˜¯å­—ç¬¦ä¸²ç±»å‹
            if pd.isna(title):  # å¤„ç†ç©ºå€¼
                continue
            title = str(title)  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            
            # æ¸…ç†æ ‡é¢˜
            clean_title = re.sub(r'[^\w\s]', '', title).strip()
            # åˆ†è¯
            keywords = [word for word in jieba.cut(clean_title) if len(word) > 1]
            title_info[title] = {
                'keywords': keywords,
                'likes': likes
            }
        
        # 2. ç»Ÿè®¡å…³é”®è¯å‡ºç°æ¬¡æ•°
        all_keywords = []
        for info in title_info.values():
            all_keywords.extend(info['keywords'])
        keyword_counter = Counter(all_keywords)
        
        # 3. æŒ‰å…³é”®è¯å¯¹æ ‡é¢˜è¿›è¡Œåˆ†ç»„
        keyword_titles = {}
        for title, info in title_info.items():
            if info['keywords']:
                main_keyword = max(info['keywords'], key=lambda x: keyword_counter[x])
                if main_keyword not in keyword_titles:
                    keyword_titles[main_keyword] = []
                keyword_titles[main_keyword].append((title, info['likes']))
        
        # 4. æ•´ç†åˆ†æç»“æœ
        for keyword, titles in keyword_titles.items():
            # æŒ‰ç‚¹èµæ•°é™åºæ’åºæ ‡é¢˜
            sorted_titles = sorted(titles, key=lambda x: x[1], reverse=True)
            title_analysis.append({
                'å…³é”®è¯': keyword,
                'å‡ºç°æ¬¡æ•°': len(titles),
                'ç›¸å…³æ ‡é¢˜': [t[0] for t in sorted_titles],  # åªä¿ç•™æ ‡é¢˜ï¼Œä¸åŒ…å«ç‚¹èµæ•°
                'æ ‡é¢˜æ•°é‡': len(titles)
            })
        
        # æŒ‰å‡ºç°æ¬¡æ•°é™åºæ’åºå…³é”®è¯
        title_analysis.sort(key=lambda x: x['å‡ºç°æ¬¡æ•°'], reverse=True)
        return title_analysis

    def highlight_keyword(self, title, keyword):
        """åœ¨æ ‡é¢˜ä¸­é«˜äº®å…³é”®è¯"""
        return title.replace(keyword, f'ã€{keyword}ã€‘')

    def save_analysis_results(self, analysis_results, keyword):
        """ä¿å­˜åˆ†æç»“æœ"""
        current_time = datetime.now().strftime('%Y%m%d_%Hç‚¹%Måˆ†')
        filename = f'æ ‡é¢˜åˆ†æ_{keyword}_{current_time}.xlsx'
        save_path = os.path.join(self.data_dir, filename)
        
        # åˆ›å»ºå·¥ä½œç°¿å’Œå·¥ä½œè¡¨
        wb = openpyxl.Workbook()
        ws_data = wb.active
        ws_data.title = 'æ ‡é¢˜åˆ†æ'
        
        # ç›´æ¥å†™å…¥æ•°æ®åˆ°DataFrame
        df_results = pd.DataFrame(analysis_results)
        df_results = df_results[['å…³é”®è¯', 'å‡ºç°æ¬¡æ•°', 'æ ‡é¢˜æ•°é‡', 'ç›¸å…³æ ‡é¢˜']]
        
        # å†™å…¥è¡¨å¤´ - ä¿®æ”¹ä¸ºæ·±ç°è‰²èƒŒæ™¯
        headers = ['å…³é”®è¯', 'å‡ºç°æ¬¡æ•°', 'æ ‡é¢˜æ•°é‡', 'ç›¸å…³æ ‡é¢˜']
        for col, header in enumerate(headers, 1):
            cell = ws_data.cell(row=1, column=col)
            cell.value = header
            cell.fill = PatternFill(start_color='808080', end_color='808080', fill_type='solid')
            cell.font = Font(color='FFFFFF', bold=True, size=12)
            cell.alignment = Alignment(wrap_text=True, vertical='center', horizontal='center')
        
        # å†™å…¥æ•°æ®
        for row_idx, row in df_results.iterrows():
            # å…³é”®è¯åˆ—
            cell = ws_data.cell(row=row_idx+2, column=1)
            cell.value = row['å…³é”®è¯']
            cell.font = Font(bold=True, size=11)
            cell.alignment = Alignment(horizontal='center', vertical='center')
            
            # å‡ºç°æ¬¡æ•°åˆ—
            cell = ws_data.cell(row=row_idx+2, column=2)
            cell.value = row['å‡ºç°æ¬¡æ•°']
            cell.alignment = Alignment(horizontal='center', vertical='center')
            
            # æ ‡é¢˜æ•°é‡åˆ—
            cell = ws_data.cell(row=row_idx+2, column=3)
            cell.value = row['æ ‡é¢˜æ•°é‡']
            cell.alignment = Alignment(horizontal='center', vertical='center')
            
            # ç›¸å…³æ ‡é¢˜åˆ—
            highlighted_titles = []
            for i, title in enumerate(row['ç›¸å…³æ ‡é¢˜'], 1):
                highlighted_title = self.highlight_keyword(title, row['å…³é”®è¯'])
                highlighted_titles.append(f"{i}. {highlighted_title}")
            
            cell = ws_data.cell(row=row_idx+2, column=4)
            cell.value = '\n'.join(highlighted_titles)
            cell.alignment = Alignment(wrap_text=True, vertical='top')
        
        # è®¾ç½®åˆ—å®½å’Œæ ¼å¼
        ws_data.column_dimensions['A'].width = 15
        ws_data.column_dimensions['B'].width = 12
        ws_data.column_dimensions['C'].width = 12
        ws_data.column_dimensions['D'].width = 100
        
        # è®¾ç½®è¡Œé«˜
        ws_data.row_dimensions[1].height = 25  # è¡¨å¤´è¡Œé«˜
        
        wb.save(save_path)
        print(f"\nåˆ†æç»“æœå·²ä¿å­˜è‡³ï¼š{filename}")

    def analyze_viral_patterns(self):
        """åˆ†æçˆ†æ¬¾æ ‡é¢˜æ¨¡æ¿"""
        # ä½¿ç”¨é…ç½®ä¸­çš„çˆ†æ¬¾é˜ˆå€¼
        VIRAL_THRESHOLD = base_config.TITLE_VIRAL_THRESHOLD
        
        # æ”¶é›†æ‰€æœ‰çˆ†æ¬¾æ ‡é¢˜
        viral_titles = []
        for _, row in self.df.iterrows():
            title = row['ç¬”è®°æ ‡é¢˜']
            likes = row.get('ç‚¹èµæ•°', 0)
            
            if pd.isna(title) or pd.isna(likes):
                continue
                
            title = str(title)
            likes = float(likes) if not isinstance(likes, (int, float)) else likes
            
            if likes >= VIRAL_THRESHOLD:
                viral_titles.append({
                    'title': title,
                    'likes': likes
                })
        
        # æå–æ‰€æœ‰çˆ†æ¬¾æ ‡é¢˜çš„å…±æ€§è¯
        all_viral_titles = [post['title'] for post in viral_titles]
        common_phrases = self.extract_common_phrases(all_viral_titles)
        
        # ä½¿ç”¨é…ç½®ä¸­çš„æ¨¡æ¿
        viral_patterns = base_config.TITLE_PATTERNS
        
        template_stats = {
            category: {
                'count': 0,
                'avg_likes': 0,
                'examples': [],
            } for category in viral_patterns
        }
        
        # åˆ†ææ¯ä¸ªæ ‡é¢˜çš„æ¨¡æ¿ç±»å‹
        for post in viral_titles:
            title = post['title']
            likes = post['likes']
            
            for category, patterns in viral_patterns.items():
                for pattern in patterns:
                    if re.search(pattern, title):
                        template_stats[category]['count'] += 1
                        template_stats[category]['examples'].append({
                            'title': title,
                            'likes': likes,
                            'matched_pattern': pattern
                        })
                        break

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        for category in template_stats:
            examples = template_stats[category]['examples']
            if examples:
                template_stats[category]['avg_likes'] = sum(e['likes'] for e in examples) / len(examples)
                template_stats[category]['examples'] = sorted(
                    examples, 
                    key=lambda x: x['likes'], 
                    reverse=True
                )[:5]
        
        template_library = self._generate_template_library(template_stats)
        return template_stats, template_library, common_phrases

    def analyze_low_follower_viral(self):
        """åˆ†æä½ç²‰çˆ†æ¬¾ç¬”è®°"""
        MIN_LIKES = base_config.TITLE_MIN_LIKES
        
        viral_posts = []
        for _, row in self.df.iterrows():
            title = row['ç¬”è®°æ ‡é¢˜']
            likes = row.get('ç‚¹èµæ•°', 0)
            followers = row.get('ç²‰ä¸æ•°', 0)
            
            if pd.isna(title) or pd.isna(likes) or pd.isna(followers):
                continue
            
            likes = float(likes) if not isinstance(likes, (int, float)) else likes
            followers = float(followers) if not isinstance(followers, (int, float)) else followers
            
            if likes > followers and likes > MIN_LIKES:
                viral_posts.append({
                    'title': str(title),
                    'likes': likes,
                    'followers': followers,
                    'ratio': likes/followers if followers > 0 else float('inf'),
                    'row_data': row
                })
        
        viral_posts.sort(key=lambda x: x['likes'], reverse=True)
        return viral_posts

    def save_low_follower_viral_results(self, viral_posts, keyword):
        """ä¿å­˜ä½ç²‰çˆ†æ¬¾åˆ†æç»“æœ"""
        if not viral_posts:
            print("\næœªå‘ç°ä½ç²‰çˆ†æ¬¾ç¬”è®°")
            return
            
        current_time = datetime.now().strftime('%Y%m%d_%Hç‚¹%Måˆ†')
        count = len(viral_posts)
        filename = f'xiaohongshu_{keyword}_{current_time} {count}æ¡.xlsx'
        save_path = os.path.join(self.data_dir, filename)
        
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = 'ä½ç²‰çˆ†æ¬¾åˆ†æ'
        
        # æ·»åŠ åˆ¤æ–­æ ‡å‡†è¯´æ˜
        ws['A1'] = f"åˆ¤æ–­æ ‡å‡†ï¼šç‚¹èµæ•°>ç²‰ä¸æ•° ä¸” ç‚¹èµæ•°>{base_config.TITLE_MIN_LIKES}"
        ws['A1'].font = Font(bold=True)
        ws.merge_cells(f'A1:{openpyxl.utils.get_column_letter(len(self.df.columns))}1')
        
        # ä½¿ç”¨åŸå§‹DataFrameçš„åˆ—åä½œä¸ºè¡¨å¤´
        headers = self.df.columns.tolist()
        for col, header in enumerate(headers, 1):
            cell = ws.cell(row=2, column=col)
            cell.value = header
            cell.font = Font(bold=True)
            cell.fill = PatternFill(start_color='808080', end_color='808080', fill_type='solid')
            cell.font = Font(color='FFFFFF', bold=True)
        
        # å†™å…¥æ•°æ®ï¼ˆä¿æŒåŸå§‹æ•°æ®çš„æ‰€æœ‰åˆ—ï¼‰
        for row_idx, post in enumerate(viral_posts, 3):
            row_data = post['row_data']
            for col_idx, value in enumerate(row_data, 1):
                cell = ws.cell(row=row_idx, column=col_idx)
                cell.value = value
                cell.alignment = Alignment(vertical='center')  # å‚ç›´å±…ä¸­
                
                # å¦‚æœæ˜¯æ ‡é¢˜åˆ—ï¼Œå¯ç”¨è‡ªåŠ¨æ¢è¡Œ
                if col_idx == 1:  # å‡è®¾æ ‡é¢˜æ˜¯ç¬¬ä¸€åˆ—
                    cell.alignment = Alignment(vertical='center', wrap_text=True)
        
        # è‡ªåŠ¨è°ƒæ•´åˆ—å®½
        for col_idx in range(1, len(headers) + 1):
            max_length = 0
            for row_idx in range(2, len(viral_posts) + 3):  # ä»è¡¨å¤´å¼€å§‹ï¼ŒåŒ…æ‹¬æ•°æ®è¡Œ
                cell = ws.cell(row=row_idx, column=col_idx)
                try:
                    if cell.value:
                        max_length = max(max_length, len(str(cell.value)))
                except:
                    pass
            adjusted_width = (max_length + 2) if max_length < 50 else 50
            ws.column_dimensions[openpyxl.utils.get_column_letter(col_idx)].width = adjusted_width
        
        wb.save(save_path)
        print(f"\nå‘ç° {count} æ¡ä½ç²‰çˆ†æ¬¾ç¬”è®°")
        print(f"ä½ç²‰çˆ†æ¬¾åˆ†æå·²ä¿å­˜è‡³ï¼š{filename}")

    def save_viral_templates(self, template_stats, template_library, common_phrases, keyword):
        """ä¿å­˜çˆ†æ¬¾æ ‡é¢˜æ¨¡æ¿åˆ†æç»“æœ"""
        current_time = datetime.now().strftime('%Y%m%d_%Hç‚¹%Måˆ†')
        filename = f'çˆ†æ¬¾æ ‡é¢˜æ¨¡æ¿_{keyword}_{current_time}.xlsx'
        save_path = os.path.join(self.data_dir, filename)
        
        wb = openpyxl.Workbook()
        
        # 1. åˆ›å»ºå…±æ€§è¯åˆ†æé¡µ
        ws_common = wb.active
        ws_common.title = 'çˆ†æ¬¾å…±æ€§è¯åˆ†æ'
        
        # æ·»åŠ åˆ¤æ–­æ ‡å‡†è¯´æ˜
        ws_common['A1'] = f"åˆ¤æ–­æ ‡å‡†ï¼šç‚¹èµæ•° >= {base_config.TITLE_VIRAL_THRESHOLD}"
        ws_common['A1'].font = Font(bold=True)
        ws_common.merge_cells('A1:C1')
        
        # å†™å…¥å…±æ€§è¯è¡¨å¤´
        headers = ['å…±æ€§è¯ç»„', 'å‡ºç°é¢‘ç‡', 'ç¤ºä¾‹æ ‡é¢˜']
        for col, header in enumerate(headers, 1):
            cell = ws_common.cell(row=2, column=col)
            cell.value = header
            cell.font = Font(bold=True)
            cell.fill = PatternFill(start_color='808080', end_color='808080', fill_type='solid')
            cell.font = Font(color='FFFFFF', bold=True)
        
        # å†™å…¥å…±æ€§è¯æ•°æ®
        row = 3
        for phrase in common_phrases:
            ws_common.cell(row=row, column=1, value=phrase['phrase'])
            ws_common.cell(row=row, column=2, value=phrase['frequency'])
            examples = '\n'.join([f"{i+1}. {title}" for i, title in enumerate(phrase['example_titles'])])
            ws_common.cell(row=row, column=3, value=examples)
            row += 1
        
        # è®¾ç½®åˆ—å®½
        ws_common.column_dimensions['A'].width = 20
        ws_common.column_dimensions['B'].width = 12
        ws_common.column_dimensions['C'].width = 60
        
        # 2. åˆ›å»ºæ¨¡æ¿åˆ†æé¡µ
        ws_analysis = wb.create_sheet(title='çˆ†æ¬¾æ ‡é¢˜åˆ†æ')
        
        # æ·»åŠ åˆ¤æ–­æ ‡å‡†è¯´æ˜
        ws_analysis['A1'] = f"åˆ¤æ–­æ ‡å‡†ï¼šç‚¹èµæ•° >= {base_config.TITLE_VIRAL_THRESHOLD}"
        ws_analysis['A1'].font = Font(bold=True)
        ws_analysis.merge_cells('A1:D1')
        
        # å†™å…¥è¡¨å¤´
        headers = ['æ¨¡æ¿ç±»å‹', 'ä½¿ç”¨é¢‘ç‡', 'å¹³å‡ç‚¹èµ', 'æˆåŠŸæ¡ˆä¾‹']
        for col, header in enumerate(headers, 1):
            cell = ws_analysis.cell(row=2, column=col)
            cell.value = header
            cell.font = Font(bold=True)
            cell.fill = PatternFill(start_color='808080', end_color='808080', fill_type='solid')
            cell.font = Font(color='FFFFFF', bold=True)
        
        row = 3
        for category, stats in template_stats.items():
            if stats['count'] > 0:
                ws_analysis.cell(row=row, column=1, value=category)
                ws_analysis.cell(row=row, column=2, value=stats['count'])
                ws_analysis.cell(row=row, column=3, value=f"{stats['avg_likes']:.0f}")
                
                examples = '\n'.join([
                    f"{i+1}. {e['title']} (ğŸ‘{e['likes']})" 
                    for i, e in enumerate(stats['examples'])
                ])
                ws_analysis.cell(row=row, column=4, value=examples)
                row += 1
        
        # 3. åˆ›å»ºæ¨¡æ¿åº“é¡µ
        ws_templates = wb.create_sheet(title='æ ‡é¢˜æ¨¡æ¿åº“')
        
        # æ·»åŠ åˆ¤æ–­æ ‡å‡†è¯´æ˜åˆ°æ¨¡æ¿åº“é¡µ
        ws_templates['A1'] = f"åˆ¤æ–­æ ‡å‡†ï¼šç‚¹èµæ•° >= {base_config.TITLE_VIRAL_THRESHOLD}"
        ws_templates['A1'].font = Font(bold=True)
        ws_templates.merge_cells('A1:D1')
        
        headers = ['ç±»å‹', 'æ¨¡æ¿', 'ç¤ºä¾‹', 'ç‚¹èµæ•°']
        for col, header in enumerate(headers, 1):
            cell = ws_templates.cell(row=2, column=col)
            cell.value = header
            cell.font = Font(bold=True)
            cell.fill = PatternFill(start_color='808080', end_color='808080', fill_type='solid')
            cell.font = Font(color='FFFFFF', bold=True)
        
        row = 3
        for category, templates in template_library.items():
            for template_info in templates:
                ws_templates.cell(row=row, column=1, value=category)
                ws_templates.cell(row=row, column=2, value=template_info['template'])
                ws_templates.cell(row=row, column=3, value=template_info['original'])
                ws_templates.cell(row=row, column=4, value=template_info['likes'])
                row += 1
        
        # è®¾ç½®åˆ—å®½
        ws_analysis.column_dimensions['A'].width = 15
        ws_analysis.column_dimensions['B'].width = 12
        ws_analysis.column_dimensions['C'].width = 12
        ws_analysis.column_dimensions['D'].width = 60
        
        ws_templates.column_dimensions['A'].width = 15
        ws_templates.column_dimensions['B'].width = 30
        ws_templates.column_dimensions['C'].width = 60
        ws_templates.column_dimensions['D'].width = 12
        
        # è®¾ç½®è‡ªåŠ¨æ¢è¡Œå’Œå¯¹é½æ–¹å¼
        for ws in [ws_common, ws_analysis, ws_templates]:
            for row in ws.iter_rows(min_row=3):
                for cell in row:
                    cell.alignment = Alignment(vertical='center', wrap_text=True)
        
        wb.save(save_path)
        print(f"\nçˆ†æ¬¾æ ‡é¢˜æ¨¡æ¿åˆ†æå·²ä¿å­˜è‡³ï¼š{filename}")

    def _generate_template_library(self, template_stats):
        """æ ¹æ®åˆ†æç»“æœç”Ÿæˆå¯å¤ç”¨çš„æ ‡é¢˜æ¨¡æ¿åº“"""
        template_library = {}
        
        for category, stats in template_stats.items():
            if not stats['examples']:
                continue
                
            templates = []
            for example in stats['examples']:
                title = example['title']
                pattern = example['matched_pattern']
                
                # æå–æ¨¡æ¿ï¼ˆæ›¿æ¢å…·ä½“è¯æ±‡ä¸ºé€šç”¨å ä½ç¬¦ï¼‰
                template = title
                template = re.sub(r'\d+', '{N}', template)  # æ›¿æ¢å…·ä½“æ•°å­—
                template = re.sub(r'[a-zA-Z\u4e00-\u9fff]+é‹', '{äº§å“}', template)  # æ›¿æ¢å…·ä½“äº§å“
                template = re.sub(r'[a-zA-Z\u4e00-\u9fff]+ç‰Œ', '{å“ç‰Œ}', template)  # æ›¿æ¢å…·ä½“å“ç‰Œ
                
                templates.append({
                    'template': template,
                    'original': title,
                    'likes': example['likes']
                })
            
            template_library[category] = templates
        
        return template_library

def main():
    """ä¸»å‡½æ•°"""
    try:
        # æŒ‡å®šè¦åˆ†æçš„æ–‡ä»¶å
        target_file = base_config.EXCEL_FILENAME
        excel_path = base_config.EXCEL_PATH
        
        if not os.path.exists(excel_path):
            print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {target_file}")
            return
        
        print(f"æ­£åœ¨åˆ†ææ–‡ä»¶: {target_file}")
        
        # è¯»å–æ•°æ®
        df = pd.read_excel(excel_path)
        print(f"æˆåŠŸåŠ è½½æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
        
        # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
        if 'ç¬”è®°æ ‡é¢˜' not in df.columns:
            print("é”™è¯¯ï¼šExcelæ–‡ä»¶ä¸­æ²¡æœ‰'ç¬”è®°æ ‡é¢˜'åˆ—ï¼")
            print("ç°æœ‰çš„åˆ—åï¼š", df.columns.tolist())
            return
            
        # æå–å…³é”®è¯
        keyword_match = re.search(r'xiaohongshu_(.+?)_', target_file)
        keyword = keyword_match.group(1) if keyword_match else 'æœªçŸ¥å…³é”®è¯'
        
        # åˆ›å»ºåˆ†æå™¨å¹¶æ‰§è¡Œåˆ†æ
        analyzer = TitleAnalyzer(df)
        analysis_results = analyzer.analyze_similar_titles()
        analyzer.save_analysis_results(analysis_results, keyword)
        
        # æ·»åŠ çˆ†æ¬¾æ ‡é¢˜åˆ†æ
        print("\nå¼€å§‹çˆ†æ¬¾æ ‡é¢˜æ¨¡æ¿åˆ†æ...")
        template_stats, template_library, common_phrases = analyzer.analyze_viral_patterns()
        analyzer.save_viral_templates(template_stats, template_library, common_phrases, keyword)
        
        # æ·»åŠ ä½ç²‰çˆ†æ¬¾åˆ†æ
        print("\nå¼€å§‹ä½ç²‰çˆ†æ¬¾åˆ†æ...")
        viral_posts = analyzer.analyze_low_follower_viral()
        analyzer.save_low_follower_viral_results(viral_posts, keyword)
        
    except Exception as e:
        print(f"åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}")
        import traceback
        print(traceback.format_exc())
    
    print("\n=== åˆ†æå®Œæˆ ===")

if __name__ == '__main__':
    main()