import pandas as pd
from collections import Counter
import os
from datetime import datetime
import re
import jieba
import openpyxl
from openpyxl.styles import PatternFill, Font, Alignment
from openpyxl.chart import PieChart, Reference
from openpyxl.chart.label import DataLabelList
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯

class TitleAnalyzer:
    def __init__(self, df):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.df = df
        self.data_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'data')
        # ç¡®ä¿dataç›®å½•å­˜åœ¨
        os.makedirs(self.data_dir, exist_ok=True)

    def extract_common_phrases(self, titles):
        """æå–æ ‡é¢˜ä¸­çš„å…±æ€§è¯ç»„"""
        # ç›¸å…³å…³é”®è¯åˆ—è¡¨
        relevant_keywords = [
            'ç©¿æ­', 'æ­é…', 'é£æ ¼', 'åˆé›†', 'æ•™ç¨‹', 'æ”»ç•¥',
            'æ¨è', 'åˆ†äº«', 'å¿…å…¥', 'å¿…å¤‡', 'æ¸…å•', 
            'ç§è‰', 'å®‰åˆ©', 'æµ‹è¯„', 'ä¸€å‘¨', 'æ­ç€',
            'å¥½çœ‹', 'æ˜¾ç˜¦', 'ç™¾æ­', 'å®ç©¿', 'èˆ’æœ',
            'æ¬¾å¼', 'å•å“', 'æµè¡Œ', 'æ—¶å°š', 'æ½®æµ'
        ]
        
        # åˆ†è¯å¹¶ç»Ÿè®¡è¯é¢‘
        word_freq = Counter()
        phrase_patterns = []
        
        # ç¬¬ä¸€æ­¥ï¼šå¯¹æ‰€æœ‰æ ‡é¢˜è¿›è¡Œåˆ†è¯
        all_words_in_titles = []
        for title in titles:
            # ä½¿ç”¨jiebaçš„æœç´¢å¼•æ“æ¨¡å¼ï¼Œæ›´å®¹æ˜“è¯†åˆ«çŸ­è¯­
            words = [w for w in jieba.cut_for_search(title) if len(w) > 1]
            all_words_in_titles.append(words)
            word_freq.update(words)
        
        # ç¬¬äºŒæ­¥ï¼šå¯»æ‰¾å…±åŒå‡ºç°çš„è¯ç»„
        common_phrases = []
        for i in range(len(all_words_in_titles)):
            words = all_words_in_titles[i]
            
            # åœ¨å•ä¸ªæ ‡é¢˜å†…å¯»æ‰¾å¯èƒ½çš„è¯ç»„
            for j in range(len(words)-1):
                for k in range(j+1, min(j+4, len(words))):  # æœ€å¤šçœ‹ç›¸é‚»çš„3ä¸ªè¯
                    phrase_words = words[j:k+1]
                    if len(phrase_words) >= 2:  # è‡³å°‘2ä¸ªè¯
                        phrase = ''.join(phrase_words)
                        # æ£€æŸ¥è¿™ä¸ªè¯ç»„åœ¨å…¶ä»–æ ‡é¢˜ä¸­çš„å‡ºç°æ¬¡æ•°
                        count = sum(1 for title in titles if phrase in title)
                        if count >= 2:  # è‡³å°‘åœ¨2ä¸ªæ ‡é¢˜ä¸­å‡ºç°
                            common_phrases.append({
                                'phrase': phrase,
                                'frequency': count,
                                'words': phrase_words,
                                'example_titles': [t for t in titles if phrase in t][:3]  # ä¿å­˜æœ€å¤š3ä¸ªç¤ºä¾‹æ ‡é¢˜
                            })
        
        # ç¬¬ä¸‰æ­¥ï¼šå»é‡å’Œæ’åº
        seen_phrases = set()
        unique_phrases = []
        for p in common_phrases:
            if p['phrase'] not in seen_phrases:
                seen_phrases.add(p['phrase'])
                unique_phrases.append(p)
        
        # æŒ‰é¢‘ç‡å’Œè¯ç»„é•¿åº¦æ’åºï¼ˆä¼˜å…ˆé€‰æ‹©é¢‘ç‡é«˜ä¸”è¾ƒé•¿çš„è¯ç»„ï¼‰
        unique_phrases.sort(key=lambda x: (x['frequency'], len(x['phrase'])), reverse=True)
        
        # ç¬¬å››æ­¥ï¼šè¿‡æ»¤æ‰ä¸å¤Ÿç›¸å…³çš„è¯ç»„
        filtered_phrases = []
        for p in unique_phrases:
            # æ£€æŸ¥è¯ç»„æ˜¯å¦æœ‰æ„ä¹‰
            if len(p['words']) >= 2 and (  # è‡³å°‘2ä¸ªè¯
                # æ¡ä»¶1ï¼šåŒ…å«ç›¸å…³å…³é”®è¯
                any(w in relevant_keywords for w in p['words']) or
                # æ¡ä»¶2ï¼šé«˜é¢‘å‡ºç°ï¼ˆå‡ºç°3æ¬¡ä»¥ä¸Šï¼‰ä¸”è¯ç»„é•¿åº¦åˆé€‚
                (p['frequency'] >= 3 and len(p['phrase']) >= 3) or
                # æ¡ä»¶3ï¼šç‰¹åˆ«é«˜é¢‘ï¼ˆå‡ºç°5æ¬¡ä»¥ä¸Šï¼‰
                p['frequency'] >= 5
            ):
                filtered_phrases.append(p)
        
        return filtered_phrases[:10]  # è¿”å›top 10å…±æ€§è¯ç»„
    def analyze_similar_titles(self):
        """åˆ†æç›¸ä¼¼æ ‡é¢˜"""
        print("\n=== å¼€å§‹æ ‡é¢˜åˆ†æ ===")
        title_analysis = []
        
        # 1. æå–æ‰€æœ‰æ ‡é¢˜çš„å…³é”®è¯
        title_info = {}  # å­˜å‚¨æ ‡é¢˜çš„å…³é”®è¯å’Œç‚¹èµæ•°
        for idx, row in self.df.iterrows():
            title = row['ç¬”è®°æ ‡é¢˜']
            likes = row.get('ç‚¹èµæ•°', 0)  # è·å–ç‚¹èµæ•°
            
            # ç¡®ä¿æ ‡é¢˜æ˜¯å­—ç¬¦ä¸²ç±»å‹
            if pd.isna(title):  # å¤„ç†ç©ºå€¼
                continue
            title = str(title)  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            
            # æ¸…ç†æ ‡é¢˜
            clean_title = re.sub(r'[^\w\s]', '', title).strip()
            # åˆ†è¯
            keywords = [word for word in jieba.cut(clean_title) if len(word) > 1]
            title_info[title] = {
                'keywords': keywords,
                'likes': likes
            }
        
        # 2. ç»Ÿè®¡å…³é”®è¯å‡ºç°æ¬¡æ•°
        all_keywords = []
        for info in title_info.values():
            all_keywords.extend(info['keywords'])
        keyword_counter = Counter(all_keywords)
        
        # 3. æŒ‰å…³é”®è¯å¯¹æ ‡é¢˜è¿›è¡Œåˆ†ç»„
        keyword_titles = {}
        for title, info in title_info.items():
            if info['keywords']:
                main_keyword = max(info['keywords'], key=lambda x: keyword_counter[x])
                if main_keyword not in keyword_titles:
                    keyword_titles[main_keyword] = []
                keyword_titles[main_keyword].append((title, info['likes']))
        
        # 4. æ•´ç†åˆ†æç»“æœ
        for keyword, titles in keyword_titles.items():
            # æŒ‰ç‚¹èµæ•°é™åºæ’åºæ ‡é¢˜
            sorted_titles = sorted(titles, key=lambda x: x[1], reverse=True)
            title_analysis.append({
                'å…³é”®è¯': keyword,
                'å‡ºç°æ¬¡æ•°': len(titles),
                'ç›¸å…³æ ‡é¢˜': [t[0] for t in sorted_titles],  # åªä¿ç•™æ ‡é¢˜ï¼Œä¸åŒ…å«ç‚¹èµæ•°
                'æ ‡é¢˜æ•°é‡': len(titles)
            })
        
        # æŒ‰å‡ºç°æ¬¡æ•°é™åºæ’åºå…³é”®è¯
        title_analysis.sort(key=lambda x: x['å‡ºç°æ¬¡æ•°'], reverse=True)
        return title_analysis

    def highlight_keyword(self, title, keyword):
        """åœ¨æ ‡é¢˜ä¸­é«˜äº®å…³é”®è¯"""
        return title.replace(keyword, f'ã€{keyword}ã€‘')

    def save_analysis_results(self, analysis_results, keyword):
        """ä¿å­˜åˆ†æç»“æœ"""
        current_time = datetime.now().strftime('%Y%m%d_%Hç‚¹%Måˆ†')
        filename = f'æ ‡é¢˜åˆ†æ_{keyword}_{current_time}.xlsx'
        save_path = os.path.join(self.data_dir, filename)
        
        # åˆ›å»ºå·¥ä½œç°¿å’Œå·¥ä½œè¡¨
        wb = openpyxl.Workbook()
        ws_data = wb.active
        ws_data.title = 'æ ‡é¢˜åˆ†æ'
        
        # ç›´æ¥å†™å…¥æ•°æ®åˆ°DataFrame
        df_results = pd.DataFrame(analysis_results)
        df_results = df_results[['å…³é”®è¯', 'å‡ºç°æ¬¡æ•°', 'æ ‡é¢˜æ•°é‡', 'ç›¸å…³æ ‡é¢˜']]
        
        # å†™å…¥è¡¨å¤´ - ä¿®æ”¹ä¸ºæ·±ç°è‰²èƒŒæ™¯
        headers = ['å…³é”®è¯', 'å‡ºç°æ¬¡æ•°', 'æ ‡é¢˜æ•°é‡', 'ç›¸å…³æ ‡é¢˜']
        for col, header in enumerate(headers, 1):
            cell = ws_data.cell(row=1, column=col)
            cell.value = header
            cell.fill = PatternFill(start_color='808080', end_color='808080', fill_type='solid')
            cell.font = Font(color='FFFFFF', bold=True, size=12)
            cell.alignment = Alignment(wrap_text=True, vertical='center', horizontal='center')
        
        # å†™å…¥æ•°æ®
        for row_idx, row in df_results.iterrows():
            # å…³é”®è¯åˆ—
            cell = ws_data.cell(row=row_idx+2, column=1)
            cell.value = row['å…³é”®è¯']
            cell.font = Font(bold=True, size=11)
            cell.alignment = Alignment(horizontal='center', vertical='center')
            
            # å‡ºç°æ¬¡æ•°åˆ—
            cell = ws_data.cell(row=row_idx+2, column=2)
            cell.value = row['å‡ºç°æ¬¡æ•°']
            cell.alignment = Alignment(horizontal='center', vertical='center')
            
            # æ ‡é¢˜æ•°é‡åˆ—
            cell = ws_data.cell(row=row_idx+2, column=3)
            cell.value = row['æ ‡é¢˜æ•°é‡']
            cell.alignment = Alignment(horizontal='center', vertical='center')
            
            # ç›¸å…³æ ‡é¢˜åˆ—
            highlighted_titles = []
            for i, title in enumerate(row['ç›¸å…³æ ‡é¢˜'], 1):
                highlighted_title = self.highlight_keyword(title, row['å…³é”®è¯'])
                highlighted_titles.append(f"{i}. {highlighted_title}")
            
            cell = ws_data.cell(row=row_idx+2, column=4)
            cell.value = '\n'.join(highlighted_titles)
            cell.alignment = Alignment(wrap_text=True, vertical='top')
        
        # è®¾ç½®åˆ—å®½å’Œæ ¼å¼
        ws_data.column_dimensions['A'].width = 15
        ws_data.column_dimensions['B'].width = 12
        ws_data.column_dimensions['C'].width = 12
        ws_data.column_dimensions['D'].width = 100
        
        # è®¾ç½®è¡Œé«˜
        ws_data.row_dimensions[1].height = 25  # è¡¨å¤´è¡Œé«˜
        
        wb.save(save_path)
        print(f"\nåˆ†æç»“æœå·²ä¿å­˜è‡³ï¼š{filename}")
    def analyze_viral_patterns(self):
        """åˆ†æçˆ†æ¬¾æ ‡é¢˜æ¨¡æ¿ï¼ˆç‚¹èµæ•° >= 1000 çš„æ ‡é¢˜ï¼‰"""
        VIRAL_THRESHOLD = 1000  # å®šä¹‰çˆ†æ¬¾æ ‡å‡†ï¼šç‚¹èµæ•° >= 1000
        
        # é¦–å…ˆæ”¶é›†æ‰€æœ‰çˆ†æ¬¾æ ‡é¢˜
        viral_titles = []
        for _, row in self.df.iterrows():
            title = row['ç¬”è®°æ ‡é¢˜']
            likes = row.get('ç‚¹èµæ•°', 0)
            
            if pd.isna(title) or pd.isna(likes):
                continue
                
            title = str(title)
            likes = float(likes) if not isinstance(likes, (int, float)) else likes
            
            if likes >= VIRAL_THRESHOLD:
                viral_titles.append({
                    'title': title,
                    'likes': likes
                })
        
        # æå–æ‰€æœ‰çˆ†æ¬¾æ ‡é¢˜çš„å…±æ€§è¯
        all_viral_titles = [post['title'] for post in viral_titles]
        common_phrases = self.extract_common_phrases(all_viral_titles)
        
        # åŸæœ‰çš„æ¨¡æ¿åˆ†æé€»è¾‘
        viral_patterns = {
            'ç´§è¿«æ„Ÿ': {
                'patterns': [
                    r'æœ‰æ•‘äº†.*',
                    r'èµ¶ç´§å­˜ä¸‹æ¥.*',
                    r'ä¸çœ‹åæ‚”.*',
                    r'é”™è¿‡.*',
                    r'é€Ÿæ”¶è—.*',
                    r'.*è¶æ—©.*',
                    r'.*æŠ“ç´§.*',
                    r'.*å¿…é¡»æ”¶è—.*',
                ],
                'examples': []
            },
            'æ•°å­—æ¸…å•': {
                'patterns': [
                    r'^\d+[ä¸ªæ¡æ‹›å¼æ¬¾].*',
                    r'.*\d+ä¸ªç§˜å¯†.*',
                    r'.*\d+æ¡é“å¾‹.*',
                    r'.*TOP\d+.*',
                    r'.*ç¬¬\d+å.*',
                    r'.*\d+æ¬¾å¿…å…¥.*',
                ],
                'examples': []
            },
            'å¼ºçƒˆæƒ…æ„Ÿ': {
                'patterns': [
                    r'.*çœŸçš„[ç»ç‰›å¤ªå¥½].*',
                    r'.*ç»ç»å­.*',
                    r'.*çˆ±äº†çˆ±äº†.*',
                    r'.*éœ‡æƒŠ.*',
                    r'.*å¤ªå¤ªå¤ª.*',
                    r'.*æ³ªæ¨.*',
                    r'.*å¹çˆ†.*',
                    r'.*æƒŠè‰³.*',
                    r'.*å¥½ç».*',
                ],
                'examples': []
            },
            'ç‹¬å®¶å‘ç°': {
                'patterns': [
                    r'.*äººä¸çŸ¥é“çš„.*',
                    r'.*ç»ˆäºæ‰¾åˆ°.*',
                    r'.*è¢«å¿½è§†çš„.*',
                    r'.*ç§˜å¯†éƒ½åœ¨è¿™.*',
                    r'.*ç§è—.*',
                    r'.*å°ä¼—.*',
                    r'.*ç¥ç§˜.*',
                    r'.*å‘ç°å®è—.*',
                ],
                'examples': []
            },
            'è§£å†³ç—›ç‚¹': {
                'patterns': [
                    r'.*å†ä¹Ÿä¸æ€•.*',
                    r'.*è§£å†³å›°æ‰°.*',
                    r'.*ä¸ç”¨æ„.*',
                    r'.*æ•™ä½ è§£å†³.*',
                    r'.*å®Œç¾è§£å†³.*',
                    r'.*ä¸€æ¬¡æ€§è§£å†³.*',
                    r'.*ä¸ç”¨æ‹…å¿ƒ.*',
                    r'.*è½»æ¾æå®š.*',
                ],
                'examples': []
            },
            'çƒ­é—¨è¶‹åŠ¿': {
                'patterns': [
                    r'.*çˆ†ç«.*',
                    r'.*å¤§ç«.*',
                    r'.*ç«é.*',
                    r'.*åˆ·å±.*',
                    r'.*çˆ†æ¬¾.*',
                    r'.*çƒ­é—¨.*',
                    r'.*æµè¡Œ.*',
                    r'.*å‡ºåœˆ.*',
                    r'.*ç«çˆ†å…¨ç½‘.*',
                ],
                'examples': []
            },
            'æ€§ä»·æ¯”': {
                'patterns': [
                    r'.*å¹³ä»·.*',
                    r'.*ä¾¿å®œ.*',
                    r'.*ç™½èœä»·.*',
                    r'.*æ€§ä»·æ¯”.*',
                    r'.*å®æƒ .*',
                    r'.*åˆ’ç®—.*',
                    r'.*çœé’±.*',
                    r'.*è¶…å€¼.*',
                    r'.*ç™¾å…ƒå†….*',
                ],
                'examples': []
            },
            'å­£èŠ‚çƒ­ç‚¹': {
                'patterns': [
                    r'.*æ–°å¹´.*',
                    r'.*åœ£è¯.*',
                    r'.*å†¬æ—¥.*',
                    r'.*ç§‹å†¬.*',
                    r'.*æ˜¥å­£.*',
                    r'.*å¤å¤©.*',
                    r'.*è¿‡å¹´.*',
                    r'.*èŠ‚æ—¥.*',
                    r'.*è·¨å¹´.*',
                ],
                'examples': []
            },
            'ä¸“ä¸šæµ‹è¯„': {
                'patterns': [
                    r'.*æµ‹è¯„.*',
                    r'.*è¯„æµ‹.*',
                    r'.*å¯¹æ¯”.*',
                    r'.*åˆ†æ.*',
                    r'.*æ¨ªè¯„.*',
                    r'.*å®æµ‹.*',
                    r'.*æ·±åº¦ä½“éªŒ.*',
                    r'.*ä½¿ç”¨æ„Ÿå—.*',
                ],
                'examples': []
            },
            'ç©¿æ­æŒ‡å—': {
                'patterns': [
                    r'.*æ­é….*',
                    r'.*ç©¿æ­.*',
                    r'.*ç©¿æ³•.*',
                    r'.*é£æ ¼.*',
                    r'.*look.*',
                    r'.*outfit.*',
                    r'.*style.*',
                    r'.*æ··æ­.*',
                ],
                'examples': []
            }
        }
        
        template_stats = {
            category: {
                'count': 0,
                'avg_likes': 0,
                'examples': [],
            } for category in viral_patterns
        }
        
        # åˆ†ææ¯ä¸ªæ ‡é¢˜çš„æ¨¡æ¿ç±»å‹
        for post in viral_titles:
            title = post['title']
            likes = post['likes']
            
            for category, data in viral_patterns.items():
                for pattern in data['patterns']:
                    if re.search(pattern, title):
                        template_stats[category]['count'] += 1
                        template_stats[category]['examples'].append({
                            'title': title,
                            'likes': likes,
                            'matched_pattern': pattern
                        })
                        break

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        for category in template_stats:
            examples = template_stats[category]['examples']
            if examples:
                template_stats[category]['avg_likes'] = sum(e['likes'] for e in examples) / len(examples)
                template_stats[category]['examples'] = sorted(
                    examples, 
                    key=lambda x: x['likes'], 
                    reverse=True
                )[:5]
        
        template_library = self._generate_template_library(template_stats)
        return template_stats, template_library, common_phrases

    def analyze_low_follower_viral(self):
        """åˆ†æä½ç²‰çˆ†æ¬¾ç¬”è®°ï¼ˆç‚¹èµæ•°>ç²‰ä¸æ•° ä¸” ç‚¹èµæ•°>100ï¼‰"""
        MIN_LIKES = 100  # æœ€ä½ç‚¹èµæ•°è¦æ±‚
        viral_posts = []
        
        for _, row in self.df.iterrows():
            title = row['ç¬”è®°æ ‡é¢˜']
            likes = row.get('ç‚¹èµæ•°', 0)
            followers = row.get('ç²‰ä¸æ•°', 0)
            
            # å¤„ç†ç©ºå€¼
            if pd.isna(title) or pd.isna(likes) or pd.isna(followers):
                continue
            
            # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
            likes = float(likes) if not isinstance(likes, (int, float)) else likes
            followers = float(followers) if not isinstance(followers, (int, float)) else followers
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºä½ç²‰çˆ†æ¬¾
            if likes > followers and likes > MIN_LIKES:
                viral_posts.append({
                    'title': str(title),
                    'likes': likes,
                    'followers': followers,
                    'ratio': likes/followers if followers > 0 else float('inf'),
                    'row_data': row  # ä¿å­˜åŸå§‹è¡Œæ•°æ®
                })
        
        # æŒ‰ç‚¹èµæ•°é™åºæ’åº
        viral_posts.sort(key=lambda x: x['likes'], reverse=True)
        return viral_posts

    def save_low_follower_viral_results(self, viral_posts, keyword):
        """ä¿å­˜ä½ç²‰çˆ†æ¬¾åˆ†æç»“æœ"""
        if not viral_posts:
            print("\næœªå‘ç°ä½ç²‰çˆ†æ¬¾ç¬”è®°")
            return
            
        current_time = datetime.now().strftime('%Y%m%d_%Hç‚¹%Måˆ†')
        count = len(viral_posts)
        filename = f'xiaohongshu_{keyword}_{current_time} {count}æ¡.xlsx'  # ä¿®æ”¹ä¸ºä¸æºæ–‡ä»¶ç›¸åŒçš„æ ¼å¼
        save_path = os.path.join(self.data_dir, filename)
        
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = 'ä½ç²‰çˆ†æ¬¾åˆ†æ'
        
        # æ·»åŠ åˆ¤æ–­æ ‡å‡†è¯´æ˜
        ws['A1'] = "åˆ¤æ–­æ ‡å‡†ï¼šç‚¹èµæ•°>ç²‰ä¸æ•° ä¸” ç‚¹èµæ•°>100"
        ws['A1'].font = Font(bold=True)
        ws.merge_cells(f'A1:{openpyxl.utils.get_column_letter(len(self.df.columns))}1')
        
        # ä½¿ç”¨åŸå§‹DataFrameçš„åˆ—åä½œä¸ºè¡¨å¤´
        headers = self.df.columns.tolist()
        for col, header in enumerate(headers, 1):
            cell = ws.cell(row=2, column=col)
            cell.value = header
            cell.font = Font(bold=True)
            cell.fill = PatternFill(start_color='808080', end_color='808080', fill_type='solid')
            cell.font = Font(color='FFFFFF', bold=True)
        
        # å†™å…¥æ•°æ®ï¼ˆä¿æŒåŸå§‹æ•°æ®çš„æ‰€æœ‰åˆ—ï¼‰
        for row_idx, post in enumerate(viral_posts, 3):
            row_data = post['row_data']
            for col_idx, value in enumerate(row_data, 1):
                cell = ws.cell(row=row_idx, column=col_idx)
                cell.value = value
                cell.alignment = Alignment(vertical='center')  # å‚ç›´å±…ä¸­
                
                # å¦‚æœæ˜¯æ ‡é¢˜åˆ—ï¼Œå¯ç”¨è‡ªåŠ¨æ¢è¡Œ
                if col_idx == 1:  # å‡è®¾æ ‡é¢˜æ˜¯ç¬¬ä¸€åˆ—
                    cell.alignment = Alignment(vertical='center', wrap_text=True)
        
        # è‡ªåŠ¨è°ƒæ•´åˆ—å®½ï¼ˆä¿®å¤åçš„ç‰ˆæœ¬ï¼‰
        for col_idx in range(1, len(headers) + 1):
            max_length = 0
            for row_idx in range(2, len(viral_posts) + 3):  # ä»è¡¨å¤´å¼€å§‹ï¼ŒåŒ…æ‹¬æ•°æ®è¡Œ
                cell = ws.cell(row=row_idx, column=col_idx)
                try:
                    if cell.value:
                        max_length = max(max_length, len(str(cell.value)))
                except:
                    pass
            adjusted_width = (max_length + 2) if max_length < 50 else 50
            ws.column_dimensions[openpyxl.utils.get_column_letter(col_idx)].width = adjusted_width
        
        wb.save(save_path)
        print(f"\nå‘ç° {count} æ¡ä½ç²‰çˆ†æ¬¾ç¬”è®°")
        print(f"ä½ç²‰çˆ†æ¬¾åˆ†æå·²ä¿å­˜è‡³ï¼š{filename}")

    def save_viral_templates(self, template_stats, template_library, common_phrases, keyword):
        """ä¿å­˜çˆ†æ¬¾æ ‡é¢˜æ¨¡æ¿åˆ†æç»“æœ"""
        current_time = datetime.now().strftime('%Y%m%d_%Hç‚¹%Måˆ†')
        filename = f'çˆ†æ¬¾æ ‡é¢˜æ¨¡æ¿_{keyword}_{current_time}.xlsx'
        save_path = os.path.join(self.data_dir, filename)
        
        wb = openpyxl.Workbook()
        
        # 1. åˆ›å»ºå…±æ€§è¯åˆ†æé¡µ
        ws_common = wb.active
        ws_common.title = 'çˆ†æ¬¾å…±æ€§è¯åˆ†æ'
        
        # æ·»åŠ åˆ¤æ–­æ ‡å‡†è¯´æ˜
        ws_common['A1'] = "åˆ¤æ–­æ ‡å‡†ï¼šç‚¹èµæ•° >= 1000"
        ws_common['A1'].font = Font(bold=True)
        ws_common.merge_cells('A1:C1')
        
        # å†™å…¥å…±æ€§è¯è¡¨å¤´
        headers = ['å…±æ€§è¯ç»„', 'å‡ºç°é¢‘ç‡', 'ç¤ºä¾‹æ ‡é¢˜']
        for col, header in enumerate(headers, 1):
            cell = ws_common.cell(row=2, column=col)
            cell.value = header
            cell.font = Font(bold=True)
            cell.fill = PatternFill(start_color='808080', end_color='808080', fill_type='solid')
            cell.font = Font(color='FFFFFF', bold=True)
        
        # å†™å…¥å…±æ€§è¯æ•°æ®
        row = 3
        for phrase in common_phrases:
            ws_common.cell(row=row, column=1, value=phrase['phrase'])
            ws_common.cell(row=row, column=2, value=phrase['frequency'])
            examples = '\n'.join([f"{i+1}. {title}" for i, title in enumerate(phrase['example_titles'])])
            ws_common.cell(row=row, column=3, value=examples)
            row += 1
        
        # è®¾ç½®åˆ—å®½
        ws_common.column_dimensions['A'].width = 20
        ws_common.column_dimensions['B'].width = 12
        ws_common.column_dimensions['C'].width = 60
        
        # 2. åˆ›å»ºæ¨¡æ¿åˆ†æé¡µ
        ws_analysis = wb.create_sheet(title='çˆ†æ¬¾æ ‡é¢˜åˆ†æ')
        
        # æ·»åŠ åˆ¤æ–­æ ‡å‡†è¯´æ˜
        ws_analysis['A1'] = "åˆ¤æ–­æ ‡å‡†ï¼šç‚¹èµæ•° >= 1000"
        ws_analysis['A1'].font = Font(bold=True)
        ws_analysis.merge_cells('A1:D1')
        
        # å†™å…¥è¡¨å¤´
        headers = ['æ¨¡æ¿ç±»å‹', 'ä½¿ç”¨é¢‘ç‡', 'å¹³å‡ç‚¹èµ', 'æˆåŠŸæ¡ˆä¾‹']
        for col, header in enumerate(headers, 1):
            cell = ws_analysis.cell(row=2, column=col)
            cell.value = header
            cell.font = Font(bold=True)
            cell.fill = PatternFill(start_color='808080', end_color='808080', fill_type='solid')
            cell.font = Font(color='FFFFFF', bold=True)
        
        row = 3
        for category, stats in template_stats.items():
            if stats['count'] > 0:
                ws_analysis.cell(row=row, column=1, value=category)
                ws_analysis.cell(row=row, column=2, value=stats['count'])
                ws_analysis.cell(row=row, column=3, value=f"{stats['avg_likes']:.0f}")
                
                examples = '\n'.join([
                    f"{i+1}. {e['title']} (ğŸ‘{e['likes']})" 
                    for i, e in enumerate(stats['examples'])
                ])
                ws_analysis.cell(row=row, column=4, value=examples)
                row += 1
        
        # 3. åˆ›å»ºæ¨¡æ¿åº“é¡µ
        ws_templates = wb.create_sheet(title='æ ‡é¢˜æ¨¡æ¿åº“')
        
        # æ·»åŠ åˆ¤æ–­æ ‡å‡†è¯´æ˜åˆ°æ¨¡æ¿åº“é¡µ
        ws_templates['A1'] = "åˆ¤æ–­æ ‡å‡†ï¼šç‚¹èµæ•° >= 1000"
        ws_templates['A1'].font = Font(bold=True)
        ws_templates.merge_cells('A1:D1')
        
        headers = ['ç±»å‹', 'æ¨¡æ¿', 'ç¤ºä¾‹', 'ç‚¹èµæ•°']
        for col, header in enumerate(headers, 1):
            cell = ws_templates.cell(row=2, column=col)
            cell.value = header
            cell.font = Font(bold=True)
            cell.fill = PatternFill(start_color='808080', end_color='808080', fill_type='solid')
            cell.font = Font(color='FFFFFF', bold=True)
        
        row = 3
        for category, templates in template_library.items():
            for template_info in templates:
                ws_templates.cell(row=row, column=1, value=category)
                ws_templates.cell(row=row, column=2, value=template_info['template'])
                ws_templates.cell(row=row, column=3, value=template_info['original'])
                ws_templates.cell(row=row, column=4, value=template_info['likes'])
                row += 1
        
        # è®¾ç½®åˆ—å®½
        ws_analysis.column_dimensions['A'].width = 15
        ws_analysis.column_dimensions['B'].width = 12
        ws_analysis.column_dimensions['C'].width = 12
        ws_analysis.column_dimensions['D'].width = 60
        
        ws_templates.column_dimensions['A'].width = 15
        ws_templates.column_dimensions['B'].width = 30
        ws_templates.column_dimensions['C'].width = 60
        ws_templates.column_dimensions['D'].width = 12
        
        # è®¾ç½®è‡ªåŠ¨æ¢è¡Œå’Œå¯¹é½æ–¹å¼
        for ws in [ws_common, ws_analysis, ws_templates]:
            for row in ws.iter_rows(min_row=3):
                for cell in row:
                    cell.alignment = Alignment(vertical='center', wrap_text=True)
        
        wb.save(save_path)
        print(f"\nçˆ†æ¬¾æ ‡é¢˜æ¨¡æ¿åˆ†æå·²ä¿å­˜è‡³ï¼š{filename}")

    def _generate_template_library(self, template_stats):
        """æ ¹æ®åˆ†æç»“æœç”Ÿæˆå¯å¤ç”¨çš„æ ‡é¢˜æ¨¡æ¿åº“"""
        template_library = {}
        
        for category, stats in template_stats.items():
            if not stats['examples']:
                continue
                
            templates = []
            for example in stats['examples']:
                title = example['title']
                pattern = example['matched_pattern']
                
                # æå–æ¨¡æ¿ï¼ˆæ›¿æ¢å…·ä½“è¯æ±‡ä¸ºé€šç”¨å ä½ç¬¦ï¼‰
                template = title
                template = re.sub(r'\d+', '{N}', template)  # æ›¿æ¢å…·ä½“æ•°å­—
                template = re.sub(r'[a-zA-Z\u4e00-\u9fff]+é‹', '{äº§å“}', template)  # æ›¿æ¢å…·ä½“äº§å“
                template = re.sub(r'[a-zA-Z\u4e00-\u9fff]+ç‰Œ', '{å“ç‰Œ}', template)  # æ›¿æ¢å…·ä½“å“ç‰Œ
                
                templates.append({
                    'template': template,
                    'original': title,
                    'likes': example['likes']
                })
            
            template_library[category] = templates
        
        return template_library

def main():
    """ä¸»å‡½æ•°"""
    try:
        BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        DATA_DIR = os.path.join(BASE_DIR, 'data')
        
        # æŒ‡å®šè¦åˆ†æçš„æ–‡ä»¶å
        target_file = "xiaohongshu_é‹å­_20241223_16ç‚¹04åˆ† 403æ¡.xlsx"
        excel_path = os.path.join(DATA_DIR, target_file)
        
        if not os.path.exists(excel_path):
            print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {target_file}")
            return
        
        print(f"æ­£åœ¨åˆ†ææ–‡ä»¶: {target_file}")
        
        # è¯»å–æ•°æ®
        df = pd.read_excel(excel_path)
        print(f"æˆåŠŸåŠ è½½æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
        
        # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
        if 'ç¬”è®°æ ‡é¢˜' not in df.columns:
            print("é”™è¯¯ï¼šExcelæ–‡ä»¶ä¸­æ²¡æœ‰'ç¬”è®°æ ‡é¢˜'åˆ—ï¼")
            print("ç°æœ‰çš„åˆ—åï¼š", df.columns.tolist())
            return
            
        # æå–å…³é”®è¯
        keyword_match = re.search(r'xiaohongshu_(.+?)_', target_file)
        keyword = keyword_match.group(1) if keyword_match else 'æœªçŸ¥å…³é”®è¯'
        
        # åˆ›å»ºåˆ†æå™¨å¹¶æ‰§è¡Œåˆ†æ
        analyzer = TitleAnalyzer(df)
        analysis_results = analyzer.analyze_similar_titles()
        analyzer.save_analysis_results(analysis_results, keyword)
        
        # æ·»åŠ çˆ†æ¬¾æ ‡é¢˜åˆ†æ
        print("\nå¼€å§‹çˆ†æ¬¾æ ‡é¢˜æ¨¡æ¿åˆ†æ...")
        template_stats, template_library, common_phrases = analyzer.analyze_viral_patterns()
        analyzer.save_viral_templates(template_stats, template_library, common_phrases, keyword)
        
        # æ·»åŠ ä½ç²‰çˆ†æ¬¾åˆ†æ
        print("\nå¼€å§‹ä½ç²‰çˆ†æ¬¾åˆ†æ...")
        viral_posts = analyzer.analyze_low_follower_viral()
        analyzer.save_low_follower_viral_results(viral_posts, keyword)
        
    except Exception as e:
        print(f"åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}")
        import traceback
        print(traceback.format_exc())
    
    print("\n=== åˆ†æå®Œæˆ ===")

if __name__ == '__main__':
    main()
